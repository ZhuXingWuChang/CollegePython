# 1 jupyter的使用

- 启动Anaconda, 然后启动jupyter, 进入一个网页.

## 1.1 new的使用

- python3: 新建一个jupyter源文件
    - 后缀是 '.ipynb'
    - 由cell组成: cell就是一行可编辑框
        - 用来根据不同的模式进行代码和笔记的编写，编写好的代码和笔记可以直接在当前文件中运行，查看运行结果。
    - code模式用来编写代码
    - markdown模式用来写笔记
- folder: 新建一个文件夹
- text file: 新建一个任意后缀的文本把文件
    - 可以写程序，但是不能在这里运行
- terminal: 新建一个基于浏览器的终端

## 1.2 快捷键的使用

- 插入cell: a, b
- 删除cell: x
- 执行cell: shift + enter
- 切换cell的模式: m(markdown模式), y(code模式)
- cell执行后: 在cell的左侧双击就可以回到cell的编辑模式
- 执行结果的收回/展开: 在执行结果左侧双击/单击
- 打开帮助文档: shift + tab
- 自动补全: tab
- 撤销: ctrl + z

## 1.3 jupyter的源文件写完后

- 可以导出: File -> Download as -> (推荐html)

# 2 爬虫概述

## 2.1 什么是爬虫

- 通过编写程序, **模拟**浏览器上网, 然后让其去互联网上抓取**数据**的过程.
    - 模拟: 浏览器就是一个最原始的爬虫工具.
    - 抓取: 抓取一整张页面的源码/局部数据.

## 2.2 爬虫的分类

- 通用爬虫:
    - 爬取一整张页面的源码数据.
- 聚焦爬虫:
    - 爬取一整张页面的局部数据(建立在通用爬虫基础之上).
- 增量式爬虫:
    - 用来监测网站数据更新的情况, 以便于爬取到网站更新出来的数据.
- 分布式爬虫:
    - 大幅度提高爬取效率(一般情况下不用, 速率太高不一定是好事).

### 注意: 微信里面的文章不可以爬(因为受法律保护), 免费公开的网站可以爬.

## 2.3 反爬机制

- 作用到门户网站中, 防止该网站被爬虫爬取.

## 2.4 反反爬策略

- 作用在爬虫程序中, 破解反爬机制而从中爬取到相关数据.

## 2.5 第一个反爬机制

- robots协议(受法律保护):
    - 一个纯文本协议, 协议中规定了可以被爬和不能被爬的数据.(Disallow不能被爬, User-agent可以被爬)
- 破解:
    - 只是做了声明, 但是没有做相应机制, 我们主观性不遵从这个协议即可.
  